{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bd4eb4e-f164-4b7c-9301-574d962a34b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "def load_and_preprocess_images_from_directory(directory, target_shape):\n",
    "    image_list = []\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            if filename.endswith(\".jpg\"):\n",
    "                img = cv2.imread(os.path.join(root, filename))\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "                img = cv2.resize(img, target_shape)  # Resize to the target shape\n",
    "                image_list.append(img)\n",
    "    return image_list\n",
    "\n",
    "# Define the target shape (e.g., 256x256)\n",
    "target_shape = (256, 256)\n",
    "\n",
    "# Load grayscale and color images from directories with subfolders\n",
    "grayscale_images = load_and_preprocess_images_from_directory(\"bw_output/\", target_shape)\n",
    "color_images = load_and_preprocess_images_from_directory(\"color_input/\", target_shape)\n",
    "print(len(grayscale_images))\n",
    "\n",
    "# Convert grayscale images to single-channel format\n",
    "grayscale_images = [cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) for img in grayscale_images]\n",
    "\n",
    "# Expand the dimensions of grayscale images to match the model input\n",
    "grayscale_images = [np.expand_dims(img, axis=-1) for img in grayscale_images]\n",
    "\n",
    "# Example: Ensure that the color images are in RGB format\n",
    "for i, img in enumerate(color_images):\n",
    "    if img.shape[2] == 1:\n",
    "        # If color images are in grayscale, convert them to RGB\n",
    "        color_images[i] = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "# Expand the dimensions of color images to match the model input\n",
    "color_images = [np.expand_dims(img, axis=-1) for img in color_images]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a21d517-a415-4bba-8c50-95023259edb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "def create_colorization_model():\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Encoder\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(256, 256, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2), padding='same'))\n",
    "    \n",
    "    # Decoder\n",
    "    model.add(layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(layers.UpSampling2D((2, 2)))\n",
    "    \n",
    "    # Output layer with 3 channels (RGB)\n",
    "    model.add(layers.Conv2D(3, (3, 3), activation='sigmoid', padding='same'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b449571c-5a6d-4ae0-b229-c5a822ff10b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Create the model\n",
    "model = create_colorization_model()\n",
    "\n",
    "# Define the custom loss function\n",
    "def custom_loss(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, dtype=tf.float32)  # Cast y_true to float32\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "# Compile the model with the updated loss function\n",
    "model.compile(optimizer='adam', loss=custom_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e89fc8c5-58f0-4784-be8c-14e623341e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "10/10 [==============================] - 49s 5s/step - loss: 20219.8672 - val_loss: 12418.6465\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 49s 5s/step - loss: 20216.0898 - val_loss: 12418.6436\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 48s 5s/step - loss: 20216.0898 - val_loss: 12418.6406\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 51s 5s/step - loss: 20216.0898 - val_loss: 12418.6406\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 51s 5s/step - loss: 20216.0898 - val_loss: 12418.6406\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 50s 5s/step - loss: 20216.0898 - val_loss: 12418.6406\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 50s 5s/step - loss: 20216.0898 - val_loss: 12418.6406\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 50s 5s/step - loss: 20216.0879 - val_loss: 12418.6387\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 51s 5s/step - loss: 20216.0898 - val_loss: 12418.6387\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 50s 5s/step - loss: 20216.0898 - val_loss: 12418.6387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x20b01d2e890>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now you can use this compiled model for training and evaluation.\n",
    "\n",
    "import numpy as np\n",
    "# Step 4: Training\n",
    "\n",
    "# Train the model on grayscale and color images\n",
    "model.fit(np.array(grayscale_images), np.array(color_images), epochs=10, batch_size=32, validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
